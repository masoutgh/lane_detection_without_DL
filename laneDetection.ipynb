{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7gtzMdLKYR01"
      },
      "source": [
        "#Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2offAfLxFFU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zVTzZD1FYUcT"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpjpaLx3-6j4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      changing camera view to bird's eye view\n",
        "in:   src and dst matrix\n",
        "out:  M & it invers transform\n",
        "\n",
        "'''\n",
        "\n",
        "def perspectiveParameters(src, dst):\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
        "\n",
        "    return M, Minv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pg0c5znxU2j"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      transforming a frame\n",
        "in:   img, M matrix and size of image\n",
        "out:  bird eye view\n",
        "\n",
        "'''\n",
        "def perspective_transform(img, M, imgShape=(1280,720)):\n",
        "\n",
        "    return cv2.warpPerspective(img, M, imgShape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vqlb8z_nTMu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      resize the image\n",
        "in:   img, size\n",
        "out:  resized image\n",
        "\n",
        "'''\n",
        "def changeSize(img, size):\n",
        "    reimg = cv.resize(img, size)\n",
        "    return reimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bM_bQTr2VER"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      RGB color space to Lab & HLS\n",
        "in:   RGB frane\n",
        "out:  M & it invers transform\n",
        "\n",
        "'''\n",
        "def changeColorSpace(img):\n",
        "\n",
        "    img_Lab = cv.cvtColor(img, cv.COLOR_BGR2Lab)\n",
        "    img_HLS = cv.cvtColor(img, cv.COLOR_BGR2HLS)\n",
        "  \n",
        "    return img_Lab[:,:,2], img_HLS[:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTFJQlScCgPa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      color frame to binary frame\n",
        "in:   frame, thresh (optional)\n",
        "out:  binary\n",
        "\n",
        "'''\n",
        "def change2binary(img, thresh=None):\n",
        "\n",
        "    img = cv.GaussianBlur(img,(11,11),0)\n",
        "\n",
        "    if thresh == None:\n",
        "        thresh = np.quantile(img, 0.99)\n",
        "\n",
        "    ret,bin = cv.threshold(img,thresh,255,cv.THRESH_BINARY)\n",
        "    \n",
        "    return bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtHjTJwVXR3X"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      cobining yellow color and white color\n",
        "in:   two binary image (yellow and white lane)\n",
        "out:  one binary image\n",
        "\n",
        "'''\n",
        "def combineYellowWhite(yellow, white):\n",
        "\n",
        "    return yellow+white"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xygUQ7tGVKm8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "      finding two main line on the left and right of the road by sliding window\n",
        "in:   binary image\n",
        "out:  cordinate of lines and windows\n",
        "\n",
        "'''\n",
        "def sliding_window(img):\n",
        "\n",
        "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
        "    midpoint = int(histogram.shape[0]//2)\n",
        "    quarter_point = int(midpoint//2)\n",
        "    leftx_base = np.argmax(histogram[quarter_point:midpoint]) + quarter_point\n",
        "    rightx_base = np.argmax(histogram[midpoint:(midpoint+quarter_point)]) + midpoint\n",
        "    nwindows = 30\n",
        "    window_height = int(img.shape[0]/nwindows)\n",
        "    nonzero = img.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "    margin = 50\n",
        "    minpix = 20\n",
        "\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "    rectangle_data = []\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        win_y_low = img.shape[0] - (window+1)*window_height\n",
        "        win_y_high = img.shape[0] - window*window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "        rectangle_data.append((win_y_low, win_y_high, win_xleft_low, win_xleft_high, win_xright_low, win_xright_high))\n",
        "\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) &\n",
        "                          (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) &\n",
        "                           (nonzerox < win_xright_high)).nonzero()[0]\n",
        "\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        if len(good_left_inds) > minpix:\n",
        "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:        \n",
        "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds] \n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds] \n",
        "\n",
        "    left_fit, right_fit = (None, None)\n",
        "\n",
        "    if len(leftx) != 0:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    if len(rightx) != 0:\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "    \n",
        "    visualization_data = (rectangle_data, histogram)\n",
        "    \n",
        "    return left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHiJ4puQfRKn"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "      Draw the detected lane over the input image.\n",
        "in:   frame and it's binary, lines, inverse matrix of transform\n",
        "out:  colored frame\n",
        "\n",
        "'''\n",
        "def draw_lane(original_img, binary_img, l_fit, r_fit, Minv):\n",
        "\n",
        "    new_img = np.copy(original_img)\n",
        "    if l_fit is None or r_fit is None:\n",
        "        return original_img\n",
        "    warp_zero = np.zeros_like(binary_img).astype(np.uint8)\n",
        "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "    h,w = binary_img.shape\n",
        "    ploty = np.linspace(0, h-1, num=h)\n",
        "    left_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
        "    right_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
        "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "    pts = np.hstack((pts_left, pts_right))\n",
        "    cv2.fillPoly(color_warp, np.int_([pts]), (0,150, 0))\n",
        "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(0,0,255), thickness=15)\n",
        "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(0,0,255), thickness=15)\n",
        "    newwarp = cv2.warpPerspective(color_warp, Minv, (w, h))\n",
        "    newwarp = cv2.resize(newwarp, (new_img.shape[1],new_img.shape[0]))\n",
        "    result = cv2.addWeighted(new_img, 1, newwarp, 0.5, 0)\n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gh_mGfUNYaYV"
      },
      "source": [
        "#Video to frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAL91hMDk5kU",
        "outputId": "ebcb6f38-8daf-4c4c-fe65-d39bf7193398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIeIfgFyfRDr",
        "outputId": "80ed1596-3bd9-4223-f64f-a0c5d891b285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/gdrive/MyDrive/DIP-final-project/video_uncolored1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 1\n",
            "    compatible_brands: mp41mp42isom\n",
            "    creation_time   : 2016-10-16T01:32:03.000000Z\n",
            "  Duration: 00:00:50.40, start: 0.000000, bitrate: 4010 kb/s\n",
            "    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 2 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2016-10-16T01:32:03.000000Z\n",
            "      handler_name    : Core Media Audio\n",
            "    Stream #0:1(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 4005 kb/s, 25 fps, 25 tbr, 25 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2016-10-16T01:32:03.000000Z\n",
            "      handler_name    : Core Media Video\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to 'out%5d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 1\n",
            "    compatible_brands: mp41mp42isom\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2016-10-16T01:32:03.000000Z\n",
            "      handler_name    : Core Media Video\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1260 fps= 16 q=-0.0 Lsize=N/A time=00:00:50.40 bitrate=N/A speed=0.638x    \n",
            "video:1038971kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -i /road.mp4 -vf fps=25 out%5d.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GxYRiYVfRAq"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "from os import listdir\n",
        "frames = [f for f in listdir('./') if 'out' in f]\n",
        "frames.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYxrVaeNuvp_"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "for frame in frames:\n",
        "    images.append(cv.imread(frame))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yV2FFmCwYhLz"
      },
      "source": [
        "#Lane detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyj3-IS7VTzX"
      },
      "outputs": [],
      "source": [
        "src = np.float32([[50, 340], [590, 340], [390, 225], [250, 225]])\n",
        "dst = np.float32([[120, 360], [ 490, 360], [490,   1], [120,   1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rLBXg0gV3SX"
      },
      "outputs": [],
      "source": [
        "result = cv.VideoWriter('result.avi',cv.VideoWriter_fourcc(*'DIVX'), 25, (1280,720))\n",
        "\n",
        "framedetected = []\n",
        "st = time.time()\n",
        "times = []\n",
        "M, Minv = perspectiveParameters(src, dst)\n",
        "\n",
        "size = (640, 360)\n",
        "\n",
        "for image in images:\n",
        "   \n",
        "    img = changeSize(image,size)\n",
        "\n",
        "    warped =  perspective_transform(img, M, size)\n",
        "\n",
        "    yellow, white = changeColorSpace(warped)\n",
        "    yellowWhite = combineYellowWhite(change2binary(yellow),change2binary(white))\n",
        "\n",
        "    left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data = sliding_window(yellowWhite)\n",
        "\n",
        "    framedetected.append( draw_lane(image, yellowWhite, left_fit, right_fit, Minv) )\n",
        "\n",
        "et = time.time()\n",
        "\n",
        "for frame in framedetected:\n",
        "    result.write(frame.astype(np.uint8))\n",
        "\n",
        "result.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtOE2BmqqheB"
      },
      "outputs": [],
      "source": [
        "!rm *.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6wfNL-Noziu",
        "outputId": "3ae59a09-b0f5-4c0c-ceeb-6f12c3bc16bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average execution time for a frame: 0.022 second\n",
            "It's equal to: 45.4 frame per second.\n"
          ]
        }
      ],
      "source": [
        "print('Average execution time for a frame:', round((et - st)/len(images),4), 'second')\n",
        "print('It\\'s equal to:', round(len(images)/(et - st),1), 'frame per second.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
